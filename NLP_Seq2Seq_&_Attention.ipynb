{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMSYKMxV3yZE3yqOJX0wTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuvita97/NLP-Machine-Translation/blob/main/NLP_Seq2Seq_%26_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X7KOiYf_uPy",
        "outputId": "b3420e54-58e3-403e-8448-1e8d01198a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Machine-Translation'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nuvita97/NLP-Machine-Translation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "p-RvauHtA-5M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'NLP-Machine-Translation'\n",
        "os.chdir(path)\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sETFUhGI_2Mk",
        "outputId": "52e26561-4e5f-4e04-d5c8-8a2e7b530f59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.md',\n",
              " '.git',\n",
              " 'train.vi.txt',\n",
              " 'NLP_Seq2Seq_&_Attention.ipynb',\n",
              " 'train.en.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_filename = 'train.en.txt'\n",
        "vi_filename = 'train.vi.txt'\n",
        "\n",
        "raw_en_lines = open(en_filename, encoding = \"utf-8\").read().strip().split(\"\\n\")\n",
        "raw_vi_lines = open(vi_filename, encoding = \"utf-8\").read().strip().split(\"\\n\")\n",
        "\n",
        "print(len(raw_en_lines))\n",
        "print(len(raw_vi_lines))"
      ],
      "metadata": {
        "id": "z9fym6ktBJSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4491601b-1ef9-40d1-be0f-329b2e86b142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133317\n",
            "133317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(raw_en_lines[:3])\n",
        "display(raw_vi_lines[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "RO4Yle0FdCMi",
        "outputId": "a777876b-073d-403c-ff92-1670e0b27ca7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Rachel Pike : The science behind a climate headline',\n",
              " 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
              " 'I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Khoa học đằng sau một tiêu đề về khí hậu',\n",
              " 'Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .',\n",
              " 'Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Punctuation : \", string.punctuation )\n",
        "print(\"Digits : \", string.digits )\n",
        "\n",
        "exclude = list(string.punctuation) + list(string.digits)\n",
        "print(\"Exclude : \", exclude)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peam41bxdVPp",
        "outputId": "abe548ec-e682-41c9-b288-cd6e92e7a468"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation :  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "Digits :  0123456789\n",
            "Exclude :  ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentence):\n",
        "  sent = sentence.lower()\n",
        "  sent = sent.strip()\n",
        "  sent = re.sub(\"'\", \" \", sent)\n",
        "  sent = re.sub(\"\\s+\", \" \", sent)\n",
        "  sent = ''.join([char for char in sent if char not in exclude])\n",
        "  sent = \"<start> \" + sent + \" <end>\"\n",
        "  return sent\n",
        "\n",
        "preprocess(\"I go to school\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SYwtwC-YdfYm",
        "outputId": "98aedd1c-2785-410c-abe7-6a253fb64854"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i go to school <end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_lines = []\n",
        "vi_lines = []\n",
        "\n",
        "min_len, max_len = 10, 50\n",
        "\n",
        "for eline, vline in zip(raw_en_lines, raw_vi_lines):\n",
        "  eline = preprocess(eline)\n",
        "  vline = preprocess(vline)\n",
        "  if(min_len < len(eline.split()) < max_len and min_len < len(vline.split()) < max_len):\n",
        "    en_lines.append(eline)\n",
        "    vi_lines.append(vline)\n",
        "\n",
        "print(len(en_lines))\n",
        "print(len(vi_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF_uPAAJdnOd",
        "outputId": "cff2eb6d-422d-46dd-d1b4-e2012dbd93bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90500\n",
            "90500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Language():\n",
        "  def __init__(self, lines):\n",
        "    self.lines = lines\n",
        "    self.word2id = {}\n",
        "    self.id2word = {}\n",
        "    self.vocab = set()\n",
        "    self.max_len = 0\n",
        "    self.min_len = 0\n",
        "    self.vocab_size = 0\n",
        "    self.init_language_param()\n",
        "\n",
        "  def init_language_param(self):\n",
        "    for line in self.lines:\n",
        "      self.vocab.update(line.split(\" \"))\n",
        "      self.word2id[\"<pad>\"] = 0\n",
        "      \n",
        "    for id, word in enumerate(self.vocab):\n",
        "      self.word2id[word] = id + 1\n",
        "    \n",
        "    for word, id in self.word2id.items():\n",
        "      self.id2word[id] = word\n",
        "    \n",
        "    self.max_len = max([len(line.split(\" \")) for line in self.lines])\n",
        "    self.min_len = min([len(line.split(\" \")) for line in self.lines])\n",
        "    self.vocab_size = len(self.vocab) + 1\n",
        "  \n",
        "  def sentence_to_vector(self, sent):\n",
        "    result = np.array([self.word2id[word] for word in sent.split(\" \")])\n",
        "    return result\n",
        " \n",
        "  def vector_to_sentence(self, vector):\n",
        "    result = \" \".join([self.id2word[id] for id in vector])\n",
        "    return result"
      ],
      "metadata": {
        "id": "ltPLG4j8d0Aj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_lang = Language(en_lines)\n",
        "tar_lang = Language(vi_lines)\n",
        "\n",
        "inp_vector = [inp_lang.sentence_to_vector(line) for line in inp_lang.lines]\n",
        "tar_vector = [tar_lang.sentence_to_vector(line) for line in tar_lang.lines]\n",
        "\n",
        "print(inp_lang.max_len, inp_lang.min_len)\n",
        "print(tar_lang.max_len, tar_lang.min_len)\n",
        "print(inp_vector[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBoCro1peAoh",
        "outputId": "0a0e5dde-a4d3-4b8d-a928-9aff1959deb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 11\n",
            "72 11\n",
            "[24037 36388 26326 19714 32038  1695 32038 34487 16689 15588 34892  6971\n",
            " 26736 34892 13241   141 27122 33030 12152  2310 34892  3389 34487 23129\n",
            " 36783 34892 28853     1  2133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_tensor = tf.keras.preprocessing.sequence.pad_sequences(inp_vector, inp_lang.max_len, padding = 'post')\n",
        "tar_tensor = tf.keras.preprocessing.sequence.pad_sequences(tar_vector, inp_lang.max_len, padding = 'post')\n",
        "\n",
        "print(inp_tensor.shape)\n",
        "print(tar_tensor.shape)\n",
        "print(inp_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wMA3fU-eRuX",
        "outputId": "2c372983-e965-468f-8dae-e5e2545a3078"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90500, 74)\n",
            "(90500, 74)\n",
            "[24037 36388 26326 19714 32038  1695 32038 34487 16689 15588 34892  6971\n",
            " 26736 34892 13241   141 27122 33030 12152  2310 34892  3389 34487 23129\n",
            " 36783 34892 28853     1  2133     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(inp_tensor, tar_tensor, test_size = 0.2)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = x_train.shape[0]\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "hidden_unit = 1024\n",
        "embedding_size = 256\n",
        "print(BUFFER_SIZE)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "tmp_x, tmp_y = next(iter(dataset))\n",
        "print(tmp_x.shape, tmp_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1f6JR2OezFy",
        "outputId": "2249350f-3b5f-4a6b-abfc-21d424f26ac3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72400, 74)\n",
            "(18100, 74)\n",
            "72400\n",
            "(32, 74) (32, 74)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encode(tf.keras.Model):\n",
        "  def __init__(self, embedding_size, vocab_size, hidden_units):\n",
        "    super(Encode, self).__init__()\n",
        "    self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
        "    self.GRU = tf.keras.layers.GRU(\n",
        "        hidden_units,\n",
        "        return_sequences=True,\n",
        "        return_state=True,\n",
        "        recurrent_initializer='glorot_uniform')\n",
        "    self.hidden_units = hidden_units\n",
        "      \n",
        "  def call(self, x, hidden_state):\n",
        "    try:\n",
        "        x = self.Embedding(x)\n",
        "    except:\n",
        "        print(x, print(inp_lang.vocab_size))          \n",
        "    outputs, last_state = self.GRU(x, hidden_state)\n",
        "    return outputs, last_state\n",
        "  \n",
        "  def init_hidden_state(self, batch_size):\n",
        "    return tf.zeros([batch_size, self.hidden_units])"
      ],
      "metadata": {
        "id": "hIN8Nevbfkcz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encode(embedding_size, inp_lang.vocab_size, hidden_unit)\n",
        "hidden_state = encoder.init_hidden_state(BATCH_SIZE)\n",
        "tmp_outputs, last_state = encoder(tmp_x, hidden_state)\n",
        "print(tmp_outputs.shape)\n",
        "print(last_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4csThyZngmfM",
        "outputId": "ecfd185d-b193-4c93-c5b4-dbe9dbd4175c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 74, 1024)\n",
            "(32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.Model):\n",
        "  def __init__(self, hidden_units):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W_out_encode = tf.keras.layers.Dense(hidden_units)\n",
        "    self.W_state = tf.keras.layers.Dense(hidden_units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, encode_outs, pre_state):\n",
        "    pre_state = tf.expand_dims(pre_state, axis = 1)\n",
        "    pre_state = self.W_state(pre_state)\n",
        "    encode_outs = self.W_out_encode(encode_outs)\n",
        "    score = self.V(tf.nn.tanh(pre_state + encode_outs))\n",
        "    context_vector = score * encode_outs\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "    return context_vector, score"
      ],
      "metadata": {
        "id": "TANJ4TUpg1Io"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = Attention(hidden_unit)\n",
        "context_vector, attention_weight = attention(tmp_outputs, last_state)\n",
        "print(context_vector.shape)\n",
        "print(attention_weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2kQ_c0Ag_rl",
        "outputId": "cdc5c7fc-116a-41f8-97ea-d166c48d884a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1024)\n",
            "(32, 74, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decode(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_units):\n",
        "    super(Decode, self).__init__()\n",
        "    self.hidden_units = hidden_units\n",
        "    self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
        "    self.Attention = Attention(hidden_units)\n",
        "    self.GRU = tf.keras.layers.GRU(\n",
        "        hidden_units,\n",
        "        return_sequences=True,\n",
        "        return_state=True,\n",
        "        recurrent_initializer='glorot_uniform')\n",
        "    self.Fc = tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "  def call(self, x, encode_outs, pre_state):\n",
        "    x = tf.expand_dims(x, axis = 1)\n",
        "    try:\n",
        "      x = self.Embedding(x)\n",
        "    except:\n",
        "      print(x)\n",
        "    \n",
        "    context_vector, attention_weight = self.Attention(encode_outs, pre_state)\n",
        "    context_vector = tf.expand_dims(context_vector, axis = 1)\n",
        "    gru_inp = tf.concat([x, context_vector], axis = -1)\n",
        "    out_gru, state = self.GRU(gru_inp)\n",
        "    out_gru = tf.reshape(out_gru, (-1, out_gru.shape[2]))\n",
        "    return self.Fc(out_gru), state"
      ],
      "metadata": {
        "id": "ISnHfIfBhClg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode = Decode(tar_lang.vocab_size, embedding_size, hidden_unit)\n",
        "decode_out, state = decode(tmp_y[:,0], tmp_outputs, last_state)\n",
        "\n",
        "print(decode_out.shape)\n",
        "print(state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpHTM6echH5x",
        "outputId": "173ea60b-8919-43e0-ca58-c160e6f92e18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 16093)\n",
            "(32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = real, logits = pred) * mask\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "EPOCHS = 100\n",
        "optimizer = tf.optimizers.Adam()\n",
        "encoder = Encode(embedding_size = embedding_size, vocab_size = inp_lang.vocab_size, hidden_units = hidden_unit)\n",
        "decoder = Decode(vocab_size = tar_lang.vocab_size, embedding_size = embedding_size, hidden_units = hidden_unit)"
      ],
      "metadata": {
        "id": "EEAagiw9hMtV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  for batch_id, (x, y) in enumerate(dataset.take(N_BATCH)):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "      first_state = encoder.init_hidden_state(batch_size= BATCH_SIZE)\n",
        "      encode_outs, last_state = encoder(x, first_state)\n",
        "      decoder_state = last_state\n",
        "      decoder_input = [tar_lang.word2id[\"<start>\"]]*BATCH_SIZE\n",
        "\n",
        "      for i in range(1, y.shape[1]):\n",
        "        decode_out, decode_state = decoder(decoder_input, encode_outs, decoder_state)\n",
        "        loss += loss_function(y[:,i], decode_out)\n",
        "        decode_input = y[:,i]\n",
        "\n",
        "      train_vars = encoder.trainable_variables  + decoder.trainable_variables\n",
        "      grads = tape.gradient(loss, train_vars)\n",
        "      optimizer.apply_gradients(zip(grads, train_vars))\n",
        "    total_loss += loss\n",
        "    print(total_loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "MIu2GVnehUuj",
        "outputId": "c5e95bc5-d21e-49d3-8aa6-352d48b41c6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277.87543\n",
            "509.47522\n",
            "734.79004\n",
            "945.0568\n",
            "1180.0043\n",
            "1378.4426\n",
            "1563.8655\n",
            "1769.3254\n",
            "1964.481\n",
            "2134.1228\n",
            "2288.3542\n",
            "2467.5786\n",
            "2628.2097\n",
            "2802.6226\n",
            "2982.5234\n",
            "3151.7625\n",
            "3320.6353\n",
            "3504.9578\n",
            "3683.8303\n",
            "3830.5964\n",
            "4013.2722\n",
            "4186.206\n",
            "4360.291\n",
            "4526.3276\n",
            "4679.39\n",
            "4852.975\n",
            "5023.179\n",
            "5186.1763\n",
            "5345.3916\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7e44d87b6f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdecode_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdecode_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-684f2df425f1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, encode_outs, pre_state)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mout_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_gru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             self.kernel, ids, weights, combiner='sum')\n\u001b[1;32m    220\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3712\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m         return gen_math_ops.mat_mul(\n\u001b[0;32m-> 3714\u001b[0;31m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6013\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6015\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(inputs):\n",
        "  print(inp_lang.vector_to_sentence(inputs[0].numpy()))\n",
        "  result = ''\n",
        "\n",
        "  hidden = encoder.init_hidden_state(batch_size=1)\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  print(enc_out.shape, dec_hidden.shape)\n",
        "  \n",
        "  dec_input = [tar_lang.word2id['<start>']]\n",
        "  for t in range(tar_lang.max_len):\n",
        "      predictions, dec_hidden = decoder(dec_input, enc_out, dec_hidden)\n",
        "      predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "      result += tar_lang.id2word[predicted_id] + ' '\n",
        "      dec_input = [predicted_id]\n",
        "  return result"
      ],
      "metadata": {
        "id": "1dfmnu5-ha_a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inp, tar in dataset.take(N_BATCH):\n",
        "  print(translate(inp[1:2,:]))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jeFeEKWk2E2",
        "outputId": "59decf17-a43b-41e6-a2a5-f64ec8b2f40d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> and you can get moral argument off the ground  then  because you aposre not treating moral principles as concrete entities  <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "(1, 74, 1024) (1, 1024)\n",
            "                                                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TONQMDfFk503"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}